{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kBvmE3ymUHGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load dependencies"
      ],
      "metadata": {
        "id": "08towGT4sI6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!pip install pytorch-lifestream"
      ],
      "metadata": {
        "id": "xZcckWHdUKIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==1.8.5\n",
        "!pip install torchvision==0.12.0"
      ],
      "metadata": {
        "id": "TEJ55HyWUK3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import libraries"
      ],
      "metadata": {
        "id": "R1KZFIPmsNBn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiQsqZtYS2_q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 21\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "dkEXfkN2CbhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "qWLmzJ6Dr9ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames.coles import ColesDataset\n",
        "from ptls.frames.coles.split_strategy import SampleSlices, SampleRandom\n",
        "from ptls.frames import PtlsDataModule\n",
        "from ptls.frames.supervised import seq_to_target\n",
        "import ptls\n",
        "\n",
        "train_dl = PtlsDataModule(\n",
        "    train_data=ColesDataset(\n",
        "        data=ptls.data_load.datasets.AugmentationDataset(\n",
        "            f_augmentations=[ptls.data_load.augmentations.DropoutTrx(trx_dropout=0.01)],\n",
        "            data=ptls.data_load.datasets.MemoryMapDataset(\n",
        "                data=ptls.data_load.datasets.parquet_dataset.ParquetDataset(\n",
        "                    i_filters=[\n",
        "                        ptls.data_load.iterable_processing.SeqLenFilter(min_seq_len=25),\n",
        "                        # ptls.data_load.iterable_processing.FeatureFilter(),\n",
        "                        ],\n",
        "                     data_files=ptls.data_load.datasets.parquet_file_scan(\n",
        "                        file_path='drive/MyDrive/ptls-experiments/scenario_age_pred/data/train_trx_file.parquet',\n",
        "                        valid_rate=0.05,\n",
        "                        return_part='train'\n",
        "                     )\n",
        "                    )\n",
        "            )\n",
        "        ),\n",
        "        splitter=SampleSlices(\n",
        "            split_count=1,\n",
        "            cnt_min=25,\n",
        "            cnt_max=75,\n",
        "        ),\n",
        "    ),\n",
        "    valid_data=ColesDataset(\n",
        "        data=ptls.data_load.datasets.MemoryMapDataset(\n",
        "                data=ptls.data_load.datasets.parquet_dataset.ParquetDataset(\n",
        "                    i_filters=[\n",
        "                        ptls.data_load.iterable_processing.FeatureFilter(),\n",
        "                        ],\n",
        "                     data_files=ptls.data_load.datasets.parquet_file_scan(\n",
        "                        file_path='drive/MyDrive/ptls-experiments/scenario_age_pred/data/train_trx_file.parquet',\n",
        "                        valid_rate=0.05,\n",
        "                        return_part='valid'\n",
        "                     )\n",
        "            )\n",
        "        ),\n",
        "        splitter=SampleSlices(\n",
        "            split_count=1,\n",
        "            cnt_min=25,\n",
        "            cnt_max=50,\n",
        "        ),\n",
        "    ),\n",
        "    train_num_workers=8,\n",
        "    train_batch_size=64,\n",
        "    valid_batch_size=256,\n",
        "    valid_num_workers=16,\n",
        ")"
      ],
      "metadata": {
        "id": "C6yo-zeGTDrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from ptls.nn import TrxEncoder\n",
        "from ptls.data_load.padded_batch import PaddedBatch\n",
        "\n",
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.0003,\n",
        "    numeric_values={'amount_rur': 'identity'},\n",
        "    embeddings={\n",
        "        'trans_date': {'in': 800, 'out': 16},\n",
        "        'small_group': {'in': 250, 'out': 16},\n",
        "    },\n",
        "    use_batch_norm_with_lens=True,\n",
        "    norm_embeddings=False,\n",
        ")\n",
        "\n",
        "trx_encoder_params_identity = dict(\n",
        "    numeric_values={\n",
        "                    'amount_rur': 'identity',\n",
        "                    'trans_date': 'identity',\n",
        "                    'small_group': 'identity',\n",
        "    },\n",
        "    use_batch_norm_with_lens=False,\n",
        "    use_batch_norm=False,\n",
        "    norm_embeddings=False,\n",
        ")\n",
        "\n",
        "trx_enc = TrxEncoder(**trx_encoder_params)\n",
        "id_trx_enc = TrxEncoder(**trx_encoder_params_identity)"
      ],
      "metadata": {
        "id": "BL_F_JGjTDnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_feats = ['trans_date', 'small_group']\n",
        "num_feats = ['amount_rur']\n",
        "all_feats = cat_feats + num_feats"
      ],
      "metadata": {
        "id": "6CQkQQaEc8ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_parquet('drive/MyDrive/ptls-experiments/scenario_age_pred/data/train_trx_file_cut.parquet')"
      ],
      "metadata": {
        "id": "G3b8aPJiAJf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_parquet('drive/MyDrive/ptls-experiments/scenario_age_pred/data/test_trx_file_cut.parquet')"
      ],
      "metadata": {
        "id": "2K88gUHwHTFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = dict()\n",
        "for feat in cat_feats:\n",
        "  vocab[feat] = list(np.unique(np.concatenate(list(train_df[feat]))))\n",
        "  vocab[feat].sort()\n",
        "  vocab[feat] += [0,]"
      ],
      "metadata": {
        "id": "f-iPc5Y_AO2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model structure"
      ],
      "metadata": {
        "id": "_bfH44elrzlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, cat_feats, num_feats, vocab, dims_of_embeddings, device, dec_hid_size, n_layers=1, dropout=0.2, bidir=False):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "\n",
        "        if isinstance(dims_of_embeddings, int):\n",
        "          dims_of_embeddings = {feat: dims_of_embeddings for feat in cat_feats}\n",
        "\n",
        "        self.input_size = sum([value for value in dims_of_embeddings.values()]) + len(num_feats)\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.cat_feats = cat_feats\n",
        "        self.num_feats = num_feats\n",
        "        self.all_feats = cat_feats + num_feats\n",
        "\n",
        "        self.embedding_layers = nn.ModuleDict()\n",
        "\n",
        "        for feat, dim_of_emb in dims_of_embeddings.items():\n",
        "          self.embedding_layers[feat] = nn.Embedding(max(vocab[feat])+1, dim_of_emb, padding_idx=0)\n",
        "\n",
        "        self.dirs = 2 if bidir else 1\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(self.input_size, hidden_size, batch_first=True, num_layers=n_layers, bidirectional=bidir)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def get_embeddings(self, input_features):\n",
        "        embed_feats = None\n",
        "\n",
        "        for i, feat in enumerate(self.all_feats):\n",
        "          if feat in self.cat_feats:\n",
        "            raw = self.embedding_layers[feat](input_features[:,:, i].type(torch.long))\n",
        "          else:\n",
        "            raw = input_features[:,:, i][:, :, None]\n",
        "\n",
        "          if embed_feats is not None:\n",
        "            embed_feats = torch.cat([embed_feats, raw], dim=2)\n",
        "          else:\n",
        "            embed_feats = raw\n",
        "        return embed_feats\n",
        "\n",
        "    def forward(self, input, hidden_0=None):\n",
        "        # (batch_size, len_seq, dim_emb) -> (batch_size, len_seq, hidden_size), (1, batch_size, hidden_size)\n",
        "        #  out[:, -1, :] == hidden_n.reshape(batch_size, hidden_size)\n",
        "        embedded = self.get_embeddings(input)\n",
        "\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # hidden_0 = torch.zeros(self.dirs * self.n_layers, embedded.shape[0], self.hidden_size, device=self.device)\\\n",
        "                                                      #  if hidden_0 is None else hidden_0\n",
        "        output, hidden_n = self.gru(embedded)\n",
        "\n",
        "        hidden_n = torch.nn.ReLU()(hidden_n)\n",
        "\n",
        "        return output, hidden_n"
      ],
      "metadata": {
        "id": "w_Rrgq2TTDLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights"
      ],
      "metadata": {
        "id": "6GWP0TLm2yyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, cat_feats, num_feats, vocab, dims_of_embeddings, device, n_layers=1, dropout=0.2):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.cat_feats = cat_feats\n",
        "        self.num_feats = num_feats\n",
        "        self.all_feats = cat_feats + num_feats\n",
        "\n",
        "        if isinstance(dims_of_embeddings, int):\n",
        "            dims_of_embeddings = {feat: dims_of_embeddings for feat in cat_feats}\n",
        "        elif isinstance(dims_of_embeddings, list):\n",
        "            assert len(dims_of_embeddings) == len(self.all_feats)\n",
        "            dims_of_embeddings = {feat: value for feat, value in zip(self.all_feats, dims_of_embeddings)}\n",
        "\n",
        "        self.input_size = sum([value for value in dims_of_embeddings.values()]) + len(num_feats)\n",
        "\n",
        "        self.embedding_layers = nn.ModuleDict()\n",
        "        for feat, dim_of_emb in dims_of_embeddings.items():\n",
        "            self.embedding_layers[feat] = nn.Embedding(max(vocab[feat])+1, dim_of_emb, padding_idx=0)\n",
        "\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(self.input_size, hidden_size, batch_first=True, num_layers=n_layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def get_embeddings(self, input):\n",
        "        out = None\n",
        "        for i, feat in enumerate(self.all_feats):\n",
        "            raw = input[:, :, i]\n",
        "            if feat in self.cat_feats:\n",
        "                raw = raw.type(torch.long)\n",
        "                emb_layer = self.embedding_layers[feat]\n",
        "                raw = emb_layer(raw.to(self.device))\n",
        "            else:\n",
        "                raw = raw[:, :, None].to(self.device)\n",
        "            if out is not None:\n",
        "                out = torch.cat([out, raw], dim=2)\n",
        "            else:\n",
        "                out = raw\n",
        "        return out\n",
        "\n",
        "    def forward(self, input_features, hidden, encoder_outputs):\n",
        "        embedded = self.get_embeddings(input_features).type(torch.float).to(self.device)\n",
        "\n",
        "        if encoder_outputs.shape[2] == hidden.shape[2] * 2:\n",
        "          encoder_outputs = (encoder_outputs[:, :, :hidden.shape[2]] + encoder_outputs[:, :, hidden.shape[2]:])/2\n",
        "\n",
        "        query_h = hidden.permute(1, 0, 2)\n",
        "        hiddens_to_decoder = []\n",
        "        attn_weights_by_layers = []\n",
        "        for i in range(query_h.shape[1]):\n",
        "          hidden_i_dec, _ = self.attention(query_h[:, i, :][:, None, :], encoder_outputs)\n",
        "          hiddens_to_decoder.append(hidden_i_dec)\n",
        "          # attn_weights_by_layers.append(attn_weights)\n",
        "\n",
        "        if encoder_outputs.shape[1] > 0:\n",
        "            hiddens_to_decoder = torch.cat(hiddens_to_decoder, dim=1).permute(1,0,2)\n",
        "        else:\n",
        "            hiddens_to_decoder = hidden\n",
        "\n",
        "        embedded = self.dropout(embedded)\n",
        "        output, hidden = self.gru(embedded, hiddens_to_decoder.contiguous())\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "hpRYqm2dog4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AeBaseline(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, cat_feats, num_feats, vocab):\n",
        "        super(AeBaseline, self).__init__()\n",
        "\n",
        "        self.enc = encoder\n",
        "        self.dec = decoder\n",
        "        self.device = device\n",
        "\n",
        "        self.cat_feats = cat_feats\n",
        "        self.num_feats = num_feats\n",
        "        self.all_feats = cat_feats + num_feats\n",
        "        self.vocab = vocab\n",
        "\n",
        "\n",
        "        self.heads = nn.ModuleDict()\n",
        "        for feat, value in self.vocab.items():\n",
        "            vocab_size = max(value)+1\n",
        "            self.heads[feat] = nn.Linear(decoder.hidden_size, vocab_size)\n",
        "        for feat in self.num_feats:\n",
        "            self.heads[feat] = nn.Linear(decoder.hidden_size, 1)\n",
        "\n",
        "\n",
        "    def new_ts_unit(self, output):\n",
        "        new_input = None\n",
        "        logits = []\n",
        "\n",
        "        for i, feat in enumerate(all_feats):\n",
        "            if feat in cat_feats:\n",
        "                predict = self.heads[feat](output)\n",
        "                logits.append(predict)\n",
        "                predict = predict.max(dim=2).indices[:, :, None]\n",
        "            else:\n",
        "                predict = self.heads[feat](output)\n",
        "\n",
        "            if new_input is None:\n",
        "                new_input = predict.type(torch.float)\n",
        "            else:\n",
        "                new_input = torch.cat([new_input, predict], dim=2)\n",
        "        return new_input, logits\n",
        "\n",
        "    def dict2tensor(self, a, all_feats):\n",
        "      # a[0].payload is a dict of features\n",
        "      input_features = []\n",
        "      minim = a[0].seq_feature_shape[1]\n",
        "      maxim = minim\n",
        "\n",
        "      for feat in all_feats:\n",
        "        if feat == all_feats[0]:\n",
        "          for raw in a[0].payload[feat]:\n",
        "            len_filled = len(raw.argwhere())\n",
        "            if len_filled < minim:\n",
        "              minim = len_filled\n",
        "\n",
        "        input_features.append(torch.cat(tuple(a[0].payload[feat])).reshape(1,-1))\n",
        "\n",
        "      input_features = torch.cat(input_features).permute(-1, 0).reshape(*a[0].seq_feature_shape, len(all_feats))\n",
        "      input_features = input_features.type(torch.float)\n",
        "\n",
        "\n",
        "      return input_features, maxim\n",
        "\n",
        "    def forward(self, input_features, minim, hidden_0=None, teacher_forcing_ratio = 0.5):\n",
        "        encoder_outputs, hidden = self.enc(input_features, hidden_0)\n",
        "\n",
        "        batch_size, len_seq, quantity_of_feats = input_features.shape\n",
        "\n",
        "        input_to_decoder = torch.zeros(batch_size, 1, quantity_of_feats).to(self.device)\n",
        "\n",
        "        if self.enc.dirs == 2:\n",
        "          hidden = [i_layer_hidden[None, :, :]  for i_layer_hidden in list(hidden)]\n",
        "          temp_hidden = []\n",
        "\n",
        "          for i in range(self.enc.n_layers):\n",
        "            temp_hid_unit = torch.cat(hidden[2*i:2*i+2], dim=0).mean(dim=0)[None,:,:]\n",
        "            temp_hidden.append(temp_hid_unit)\n",
        "\n",
        "          hidden = torch.cat(temp_hidden, dim=0).to(self.device)\n",
        "\n",
        "        predicts = []\n",
        "        all_logits = []\n",
        "        for i in range(minim):\n",
        "            output, hidden = self.dec(input_to_decoder, hidden, encoder_outputs[:, :i, :])\n",
        "            input_new, logits = self.new_ts_unit(output)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input_to_decoder = input_features[:, i, :][:, None, :].to(self.device) if teacher_force else input_new\n",
        "            predicts.append(input_new) # was -- input_to_decoder\n",
        "            all_logits.append(logits)\n",
        "\n",
        "        predicts = torch.cat(predicts, dim=1)\n",
        "\n",
        "        logits_to_out = []\n",
        "\n",
        "        for i, feat in enumerate(self.all_feats):\n",
        "          if feat in self.cat_feats:\n",
        "            pred = [probs[i] for probs in all_logits]\n",
        "            pred = torch.cat(pred, dim=1)\n",
        "          else:\n",
        "            pred = predicts[:, :, i][:, :, None]\n",
        "          logits_to_out.append(pred)\n",
        "\n",
        "        return predicts, logits_to_out"
      ],
      "metadata": {
        "id": "aqKMof7gxwQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definition"
      ],
      "metadata": {
        "id": "Z0PObQnArvgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dims = {\n",
        "                   'trans_date': 32,\n",
        "                   'small_group': 32,\n",
        "                   }\n",
        "enc_hid_size = 512\n",
        "dec_hid_size = 512\n",
        "\n",
        "enc = EncoderRNN(enc_hid_size, cat_feats, num_feats, vocab, embedding_dims, device, dec_hid_size, bidir=False, n_layers=1)\n",
        "dec = DecoderRNN(dec_hid_size, cat_feats, num_feats, vocab, embedding_dims, device, n_layers=1)\n",
        "\n",
        "model = AeBaseline(enc, dec, device, cat_feats, num_feats, vocab).to(device)\n"
      ],
      "metadata": {
        "id": "uQlTvTK88rpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "ImEApRGGrP4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train epoch"
      ],
      "metadata": {
        "id": "jFnM3s9prZwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, model, optimizer, cat_loss, num_loss, teacher_forcing=0.5):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    data_length = 0\n",
        "    for iteration, data in enumerate(tqdm.tqdm(dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prepared_data, minim = model.dict2tensor(data, model.all_feats)\n",
        "        prepared_data = prepared_data.to(device)\n",
        "        data_length += prepared_data.shape[0]\n",
        "        predicted, logits = model(prepared_data, minim, teacher_forcing_ratio=teacher_forcing)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for i, feat in enumerate(model.all_feats):\n",
        "          if feat in model.cat_feats:\n",
        "            # target = F.one_hot(prepared_data[:, :minim, i].type(torch.long), max(model.vocab[feat])+1).type(torch.float)\n",
        "            target = prepared_data[:, :minim, i].type(torch.long)\n",
        "            logit_pred = logits[i].permute(0, 2, 1)\n",
        "            loss += cat_loss(logit_pred, target) #* max(model.vocab[feat]) #.detach().cpu().numpy()\n",
        "          else:\n",
        "            target = prepared_data[:, :minim, i][:, :, None]\n",
        "            masked_target = target != 0\n",
        "            pred = predicted[:, :, i][:, :, None]\n",
        "            loss_temp = num_loss(target, pred)*masked_target    #.detach().cpu().numpy()\n",
        "            loss += loss_temp.mean()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / data_length"
      ],
      "metadata": {
        "id": "MPVHrx2nrT4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate func"
      ],
      "metadata": {
        "id": "6mQOd_clrdfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model, cat_metric, num_metric):\n",
        "    model.eval()\n",
        "    metrics = dict(zip(model.all_feats, [0 for i in range(len(model.all_feats))]))\n",
        "    count_of_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(dataloader):\n",
        "            vdata, minim = model.dict2tensor(vdata, model.all_feats)\n",
        "            vdata = vdata.to(device)\n",
        "            predicted, logits = model(vdata, minim, teacher_forcing_ratio=0.0)\n",
        "            count_of_samples += vdata.shape[0] * vdata.shape[1]\n",
        "            for i, feat in enumerate(model.all_feats):\n",
        "                if feat in model.cat_feats:\n",
        "                    metrics[feat] += (predicted[:, :, i] == vdata[:, :minim, i]).sum().type(torch.float).item()\n",
        "                else:\n",
        "                    metrics[feat] += ((predicted[:, :, i] - vdata[:, :minim, i])**2).sum().type(torch.float).item()\n",
        "\n",
        "\n",
        "    for feat, metric_value in metrics.items():\n",
        "      metrics[feat] /= count_of_samples\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "HbeW1JM1rTwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train main"
      ],
      "metadata": {
        "id": "yrL8UkJRrjTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "cat_loss =  nn.CrossEntropyLoss(ignore_index=0)\n",
        "num_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "n_epochs = 150\n",
        "teacher_forcing = 0.5\n",
        "steps_teacher_forcing = 4\n",
        "gamma_teacher_forcing = 0.8\n",
        "step_size_lr = 30\n",
        "gamma_lr = 0.9025\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size_lr, gamma=gamma_lr)\n",
        "\n",
        "min_loss = None\n",
        "model_name = 'age_pred_model_gru.p'\n",
        "\n",
        "plot_losses = []\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  if epoch % steps_teacher_forcing == 0:\n",
        "      teacher_forcing *= gamma_teacher_forcing\n",
        "\n",
        "  loss = train_epoch(train_dl.train_dataloader(), model, optimizer, cat_loss, num_loss, teacher_forcing=teacher_forcing)\n",
        "  if min_loss is None:\n",
        "    min_loss = loss\n",
        "  else:\n",
        "    if loss < min_loss:\n",
        "      min_loss = loss\n",
        "      torch.save(model.state_dict(), 'drive/MyDrive/ae_baseline_model/best_' + model_name)\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  print(f\"epoch {epoch}; loss {loss}\")\n",
        "  plot_losses.append(loss)\n",
        "  torch.save(model.state_dict(), 'drive/MyDrive/ae_baseline_model/' + model_name)\n",
        "  if epoch % 15 == 0:\n",
        "    evaluate_metrics = evaluate(train_dl.val_dataloader(), model, None, None)\n",
        "    print(evaluate_metrics)\n",
        "\n",
        "plt.plot(plot_losses)"
      ],
      "metadata": {
        "id": "KgWgQa0F8qwE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference and embedding validation"
      ],
      "metadata": {
        "id": "VRR0zOSaq3CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference + saving embeddings"
      ],
      "metadata": {
        "id": "ZLxrCJzBsqMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/ae_baseline_model/ae_model.p'\n",
        "embeddings_path = '/content/drive/MyDrive/ae_data/ae_model.csv'\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "all_df = pd.concat([train_df, test_df]).set_index('client_id')\n",
        "all_df.index = all_df.index.astype(np.int64)\n",
        "\n",
        "embs_of_seqs = []\n",
        "target_labels = []\n",
        "for i in tqdm.tqdm(range(all_df.shape[0])):\n",
        "# for i in tqdm.tqdm(range(100)):\n",
        "  input_tensor = torch.zeros(1, all_df.iloc[i]['small_group'].shape[0], len(all_feats))\n",
        "  for j, feat in enumerate(all_feats):\n",
        "    input_tensor[:, :, j] = torch.tensor(all_df.iloc[i][feat])\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    try:\n",
        "      _, hidden = model.enc(input_tensor.to(device))\n",
        "    except:\n",
        "      for j, feat in enumerate(cat_feats):\n",
        "        # print(max(vocab[feat]), all_df.iloc[i][feat].max(), feat)\n",
        "        replace_to_pad = np.vectorize(lambda x: x if x <= max(vocab[feat]) else 0 )\n",
        "        input_tensor[:, :, j] = torch.tensor(replace_to_pad(all_df.iloc[i][feat]))\n",
        "      _, hidden = model.enc(input_tensor.to(device))\n",
        "\n",
        "  hidden = hidden.reshape(-1).detach().cpu().numpy()\n",
        "\n",
        "  target_labels.append(all_df.iloc[i]['target'])\n",
        "  embs_of_seqs.append(hidden)\n",
        "\n",
        "df_of_embs = pd.DataFrame(embs_of_seqs)"
      ],
      "metadata": {
        "id": "n8pRceFQrAVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = pd.read_csv(\n",
        "    '/content/drive/MyDrive/ptls-experiments/scenario_age_pred/data/train_target_cut.csv'\n",
        "    )"
      ],
      "metadata": {
        "id": "5UF26IYuGv_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets.columns"
      ],
      "metadata": {
        "id": "kr-kCXrSHf7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = all_df.merge(targets[['client_id','has_rare_small_group', 'amount_group']], on='client_id', how='left')"
      ],
      "metadata": {
        "id": "x3XPwkISHDQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_of_embs = df_of_embs.set_index(all_df.client_id)\n",
        "df_of_embs = df_of_embs.merge(all_df.reset_index()[['client_id' , 'target', 'has_rare_small_group', 'amount_group']],\n",
        "                              how='left', on='client_id')\n",
        "df_of_embs.to_csv(embeddings_path, index=False)"
      ],
      "metadata": {
        "id": "JCeyEZze0HGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## emb validation"
      ],
      "metadata": {
        "id": "x-rCwu2-snWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import random"
      ],
      "metadata": {
        "id": "QHlFH24ibma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ae_data/best_new_ae_512_tf0_max_epoch_age_pred_cut.csv', index_col='client_id')\n",
        "test_ids = pd.read_csv('/content/drive/MyDrive/ptls-experiments/scenario_age_pred/data/test_ids_file.csv')\n",
        "TARGET_COLS = ['target', 'has_rare_small_group', 'amount_group']"
      ],
      "metadata": {
        "id": "-5Lpz9KTU6JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 21\n",
        "np.random.seed(21)\n",
        "random.seed(21)\n",
        "\n",
        "TARGET_COLS = [col for col in df.columns if col in TARGET_COLS]\n",
        "TARGET_COLUMN = TARGET_COLS[2]\n",
        "\n",
        "df_train = df[df.index.isin(test_ids['client_id']) == False]\n",
        "df_train, targets_train = df_train.drop(TARGET_COLS, axis=1), df_train[TARGET_COLUMN]\n",
        "\n",
        "df_test = df[df.index.isin(test_ids['client_id'])]\n",
        "df_test, targets_test = df_test.drop(TARGET_COLS, axis=1), df_test[TARGET_COLUMN]"
      ],
      "metadata": {
        "id": "a0vEZrE0d59y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "UiCNqK3P-Vtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "indexes = np.arange(len(targets_train))\n",
        "\n",
        "arr_acc_test = []\n",
        "arr_auc_test = []\n",
        "arr_acc_val = []\n",
        "arr_auc_val = []\n",
        "\n",
        "clf = pipe = make_pipeline(\n",
        "        MaxAbsScaler(),\n",
        "        LogisticRegression(\n",
        "            random_state=21,\n",
        "            max_iter=1000000,\n",
        "            multi_class='ovr'\n",
        "        )\n",
        "    )\n",
        "binary_clf = False\n",
        "\n",
        "if targets_train.unique().shape[0] == 2:\n",
        "    binary_clf = True\n",
        "\n",
        "for train, val in kf.split(indexes, targets_train):\n",
        "  X_train, X_val, y_train, y_val = df_train.iloc[train], df_train.iloc[val], targets_train.iloc[train], targets_train.iloc[val]\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  acc_test = clf.score(df_test, targets_test)\n",
        "  acc_val = clf.score(X_val, y_val)\n",
        "\n",
        "  if binary_clf:\n",
        "      pred_label_test = clf.predict_proba(df_test)[:, 1]\n",
        "      pred_label_val = clf.predict_proba(X_val)[:, 1]\n",
        "  else:\n",
        "      pred_label_test = clf.predict_proba(df_test)\n",
        "      pred_label_val = clf.predict_proba(X_val)\n",
        "\n",
        "  auc_test = roc_auc_score(targets_test, pred_label_test, average='macro', multi_class='ovr')\n",
        "  auc_val = roc_auc_score(y_val, pred_label_val, average='macro', multi_class='ovr')\n",
        "\n",
        "  arr_acc_test.append(acc_test)\n",
        "  arr_auc_test.append(auc_test)\n",
        "  arr_acc_val.append(acc_val)\n",
        "  arr_auc_val.append(auc_val)\n",
        "\n",
        "arr_acc_test = np.array(arr_acc_test)\n",
        "arr_auc_test = np.array(arr_auc_test)\n",
        "arr_acc_val = np.array(arr_acc_val)\n",
        "arr_auc_val = np.array(arr_auc_val)\n",
        "\n",
        "\n",
        "clf.fit(df_train, targets_train)\n",
        "acc = clf.score(df_test, targets_test)\n",
        "if binary_clf:\n",
        "    pred_label = clf.predict_proba(df_test)[:, 1]\n",
        "else:\n",
        "    pred_label = clf.predict_proba(df_test)\n",
        "\n",
        "roc_auc = roc_auc_score(targets_test, pred_label, average='macro', multi_class='ovr')\n",
        "\n",
        "print(TARGET_COLUMN)\n",
        "print('Val:  acc_mean: {0}, auc_mean: {1}, acc_std: {2}, auc_std: {3}'.\\\n",
        "          format(arr_acc_val.mean(), arr_auc_val.mean(), arr_acc_val.std(), arr_auc_val.std()))\n",
        "print('Test: acc_mean: {0}, auc_mean: {1}, acc_std: {2}, auc_std: {3}'.\\\n",
        "          format(arr_acc_test.mean(), arr_auc_test.mean(), arr_acc_test.std(), arr_auc_test.std()))\n",
        "print('Full trained model: acc: {0}, auc: {1}'.format(acc, roc_auc))"
      ],
      "metadata": {
        "id": "lhdYc_XJfgPS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}